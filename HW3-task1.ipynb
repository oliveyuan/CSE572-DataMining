{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7986401,"sourceType":"datasetVersion","datasetId":4701131}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## test 2","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport time\nfrom scipy.spatial.distance import cdist","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:02:20.472259Z","iopub.execute_input":"2024-03-31T21:02:20.472787Z","iopub.status.idle":"2024-03-31T21:02:21.257760Z","shell.execute_reply.started":"2024-03-31T21:02:20.472740Z","shell.execute_reply":"2024-03-31T21:02:21.256441Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/hw3-data/data.csv\",header=None).values\nlabel = pd.read_csv(\"/kaggle/input/hw3-data/label.csv\",header=None).values.reshape(-1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:02:21.260380Z","iopub.execute_input":"2024-03-31T21:02:21.261640Z","iopub.status.idle":"2024-03-31T21:02:22.220708Z","shell.execute_reply.started":"2024-03-31T21:02:21.261545Z","shell.execute_reply":"2024-03-31T21:02:22.219369Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Q1 : Compare the SSEs","metadata":{}},{"cell_type":"code","source":"# ======== Euclidean =========\ndef euclidean_distance(a, b):\n    return np.linalg.norm(a - b)\n\n# ======== 1 - cosine =========\ndef cosine_similarity(a, b):\n    return 1 - np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\n# ======== 1 - jaccard =========\ndef jaccard_similarity(a, b):\n    return 1 - np.sum(np.minimum(a, b)) / np.sum(np.maximum(a, b))","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:02:22.222655Z","iopub.execute_input":"2024-03-31T21:02:22.223705Z","iopub.status.idle":"2024-03-31T21:02:22.235056Z","shell.execute_reply.started":"2024-03-31T21:02:22.223644Z","shell.execute_reply":"2024-03-31T21:02:22.233031Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# ======== K_Means Class =========\ndef KMeans(data, k, similarity, max_iterations=500):\n    #======= init get random centroid =========\n    centroids = random.sample(list(data), k)\n    iterations = 0\n    pre_sse = 0\n    \n    while True:\n        # ========== Assign data point to its closest centroid ==========\n        clusters = [[] for i in range(k)]\n        for datapoint in data:\n            distances = [similarity(datapoint, centroid) for centroid in centroids]\n            cluster_index = np.argmin(distances)\n            clusters[cluster_index].append(datapoint)\n        \n        # ========== Calculate new centroid for each cluster ============\n        new_centroids = []\n        \n        # ========== Calculate SSE ============\n        sse = 0\n        for i in range(k):\n            cluster = clusters[i]\n            if len(cluster) == 0:\n                new_centroids.append(centroids[i])\n                continue\n            centroid = np.mean(cluster, axis=0)\n            new_centroids.append(centroid)\n            sse += np.sum([similarity(datapoint, centroid) for datapoint in cluster])\n        \n        # ============== Check for convergence ===========\n        if np.allclose(new_centroids, centroids) or sse >= pre_sse or iterations >= max_iterations:\n            break\n        \n        # ============ Update the centroids & SSE =============\n        centroids = new_centroids\n        pre_sse = sse\n        iterations += 1\n    \n    return clusters, centroids, sse","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:02:22.239147Z","iopub.execute_input":"2024-03-31T21:02:22.240219Z","iopub.status.idle":"2024-03-31T21:02:22.255814Z","shell.execute_reply.started":"2024-03-31T21:02:22.240152Z","shell.execute_reply":"2024-03-31T21:02:22.254268Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"k = len(np.unique(label))\nprint(\"k = \", k)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:02:22.257985Z","iopub.execute_input":"2024-03-31T21:02:22.259454Z","iopub.status.idle":"2024-03-31T21:02:22.276390Z","shell.execute_reply.started":"2024-03-31T21:02:22.259366Z","shell.execute_reply":"2024-03-31T21:02:22.274327Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"k =  10\n","output_type":"stream"}]},{"cell_type":"code","source":"clusters_euclidean, centroids_euclidean, sse_euclidean = KMeans(data, k, euclidean_distance)\nclusters_cosine, centroids_cosine, sse_cosine = KMeans(data, k, cosine_similarity)\nclusters_jaccard, centroids_jaccard, sse_jaccard = KMeans(data, k, jaccard_similarity)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:02:22.278770Z","iopub.execute_input":"2024-03-31T21:02:22.279718Z","iopub.status.idle":"2024-03-31T21:02:29.836110Z","shell.execute_reply.started":"2024-03-31T21:02:22.279654Z","shell.execute_reply":"2024-03-31T21:02:29.834469Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(\"Euclidean SSE =  \", sse_euclidean)\nprint(\"Cosine SSE =  \", sse_cosine)\nprint(\"Jaccard SSE =  \", sse_jaccard)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:02:29.838252Z","iopub.execute_input":"2024-03-31T21:02:29.838922Z","iopub.status.idle":"2024-03-31T21:02:29.849036Z","shell.execute_reply.started":"2024-03-31T21:02:29.838856Z","shell.execute_reply":"2024-03-31T21:02:29.847228Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Euclidean SSE =   16345318.58205824\nCosine SSE =   2874.384098022427\nJaccard SSE =   6492.014557631396\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Q2 : Compare the accuracies","metadata":{}},{"cell_type":"code","source":"class KMeans:\n    def __init__(self, k=10, max_iter=100, distance_metric=euclidean_distance):\n        self.k = k\n        self.max_iter = max_iter\n        self.distance_metric = distance_metric\n   \n    # ============== fit for KMeans Model ===========\n    def fit(self, data):\n        # ==== init centroids ===\n        rowNum = data.shape[0]\n        self.centroids = data[np.random.choice(rowNum, self.k, replace=False)]\n        \n        \n        for i in range(self.max_iter):\n            \n            clusters = []\n            for _ in range(self.k):\n                clusters.append([])\n            \n            for datapoint in data:\n                #  ====== calculates distance to each centroid =========\n                distances = [self.distance_metric(datapoint, centroid) for centroid in self.centroids]\n                cluster = np.argmin(distances)\n                 #  ====== assigns the data point to the nearest centroid's cluster ========= \n                clusters[cluster].append(datapoint)\n                \n            new_centroids = []\n            for cluster in clusters:\n                if len(cluster) == 0:\n                    new_centroids.append(np.zeros(data.shape[1]))\n                else:\n                    new_centroids.append(np.mean(cluster, axis=0))\n                    \n            # ============== Check for convergence ===========\n            if np.allclose(self.centroids, new_centroids):\n                break\n            self.centroids = new_centroids\n    \n    # ============== Predict class ===========\n    def predict(self, data):\n        distances = []\n        for datapoint in data:\n            datapoint_distances = []\n            for centroid in self.centroids:\n                distance = self.distance_metric(datapoint, centroid)\n                datapoint_distances.append(distance)\n            distances.append(datapoint_distances)\n        distances = np.array(distances)\n        return np.argmin(distances, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:02:29.850911Z","iopub.execute_input":"2024-03-31T21:02:29.851510Z","iopub.status.idle":"2024-03-31T21:02:29.875683Z","shell.execute_reply.started":"2024-03-31T21:02:29.851449Z","shell.execute_reply":"2024-03-31T21:02:29.874065Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# ========Accuracy class=========\ndef Accuracy(predicted, actual):\n    count = 0\n    total = len(label)\n    for i in range(total):\n        if predicted[i] == actual[i]:\n            count += 1\n    return (count/total)*100","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:02:29.877690Z","iopub.execute_input":"2024-03-31T21:02:29.878110Z","iopub.status.idle":"2024-03-31T21:02:29.894072Z","shell.execute_reply.started":"2024-03-31T21:02:29.878076Z","shell.execute_reply":"2024-03-31T21:02:29.892340Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# ========euclidean predictions=========\neuclideanKM = KMeans(k=10, max_iter=100, distance_metric=euclidean_distance)\neuclideanKM.fit(data)\neuclidean_predictions = euclideanKM.predict(data)\n\n# ========cosine predictions=========\ncosineKM = KMeans(k=10, max_iter=100, distance_metric=cosine_similarity)\ncosineKM.fit(data)\ncosine_predictions = cosineKM.predict(data)\n\n# ========jaccard  predictions=========\njaccardKM = KMeans(k=10, max_iter=100, distance_metric=jaccard_similarity)\njaccardKM.fit(data)\njaccard_predictions = jaccardKM.predict(data)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:02:29.898983Z","iopub.execute_input":"2024-03-31T21:02:29.899476Z","iopub.status.idle":"2024-03-31T21:09:02.211302Z","shell.execute_reply.started":"2024-03-31T21:02:29.899429Z","shell.execute_reply":"2024-03-31T21:09:02.209541Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(\"Euclidean accuracy = \",Accuracy(euclidean_predictions,label))\nprint(\"Cosine accuracy = \",Accuracy(cosine_predictions,label))\nprint(\"Jaccard accuracy = \",Accuracy(jaccard_predictions,label))","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:09:02.214290Z","iopub.execute_input":"2024-03-31T21:09:02.214842Z","iopub.status.idle":"2024-03-31T21:09:02.244039Z","shell.execute_reply.started":"2024-03-31T21:09:02.214791Z","shell.execute_reply":"2024-03-31T21:09:02.242604Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Euclidean accuracy =  18.61\nCosine accuracy =  4.7\nJaccard accuracy =  9.44\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Q3: Set up the same stop criteria, get iterations and times to converge","metadata":{}},{"cell_type":"code","source":"class KMeans:\n    def __init__(self, k=10, max_iter=100, distance_metric=euclidean_distance, seed=99):\n        self.k = k\n        self.max_iter = max_iter\n        self.distance_metric = distance_metric\n        self.seed = seed\n    \n    def fit(self, data):\n        \n        # ===== Set the seed for NumPy's random number generator ====\n        np.random.seed(self.seed)\n        rowNum = data.shape[0]\n        self.centroids = data[np.random.choice(rowNum, self.k, replace=False)]\n        \n        prev_sse = np.inf\n        start_time = time.time()\n        for i in range(self.max_iter):\n            clusters = []\n            for _ in range(self.k):\n                clusters.append([])\n                \n            for datapoint in data:\n                distances = [self.distance_metric(datapoint, centroid) for centroid in self.centroids]\n                cluster = np.argmin(distances)\n                clusters[cluster].append(datapoint)\n            new_centroids = []\n            \n            for cluster in clusters:\n                if len(cluster) == 0:\n                    new_centroids.append(np.zeros(X.shape[1]))\n                else:\n                    new_centroids.append(np.mean(cluster, axis=0))\n            \n            \n            sse = 0\n            for cluster, centroid in zip(clusters, new_centroids):\n                sse += np.sum((cluster - centroid) ** 2)\n                \n            # ==== no change in centroid position OR SSE value increases in the next iteration ====\n            if np.allclose(self.centroids, new_centroids) or sse > prev_sse:\n                break\n                \n            self.centroids = new_centroids\n            prev_sse = sse\n    \n        end_time = time.time() \n        self.convergence_time = end_time - start_time\n            \n    def predict(self, data):\n        distances = []\n        for datapoint in data:\n            datapoint_distances = []\n            for centroid in self.centroids:\n                distance = self.distance_metric(datapoint, centroid)\n                datapoint_distances.append(distance)\n            distances.append(datapoint_distances)\n        distances = np.array(distances)\n        return np.argmin(distances, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:09:02.246347Z","iopub.execute_input":"2024-03-31T21:09:02.246860Z","iopub.status.idle":"2024-03-31T21:09:02.265699Z","shell.execute_reply.started":"2024-03-31T21:09:02.246818Z","shell.execute_reply":"2024-03-31T21:09:02.263504Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"euclideanKM = KMeans(k=10, max_iter=500, distance_metric=euclidean_distance)\neuclideanKM.fit(data)\n\ncosineKM = KMeans(k=10, max_iter=500, distance_metric=cosine_similarity)\ncosineKM.fit(data)\n\njaccardKM = KMeans(k=10, max_iter=500, distance_metric=jaccard_similarity)\njaccardKM.fit(data)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:09:02.267827Z","iopub.execute_input":"2024-03-31T21:09:02.268280Z","iopub.status.idle":"2024-03-31T21:14:05.035041Z","shell.execute_reply.started":"2024-03-31T21:09:02.268246Z","shell.execute_reply":"2024-03-31T21:14:05.033298Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(\"Euclidean converged in {} iterations\".format(len(euclideanKM.centroids)))\nprint(\"Euclidean take {}\".format(euclideanKM.convergence_time), \" to converged\")\nprint(\"======================================\")\nprint(\"Cosine converged in {} iterations\".format(len(cosineKM.centroids)))\nprint(\"Cosine take {}\".format(cosineKM.convergence_time), \" to converged\")\nprint(\"======================================\")\nprint(\"Jaccard converged in {} iterations\".format(len(jaccardKM.centroids)))\nprint(\"Jaccard take {}\".format(jaccardKM.convergence_time), \" to converged\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:14:05.037492Z","iopub.execute_input":"2024-03-31T21:14:05.038178Z","iopub.status.idle":"2024-03-31T21:14:05.051643Z","shell.execute_reply.started":"2024-03-31T21:14:05.038121Z","shell.execute_reply":"2024-03-31T21:14:05.049810Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Euclidean converged in 10 iterations\nEuclidean take 155.50824642181396  to converged\n======================================\nCosine converged in 10 iterations\nCosine take 75.82860040664673  to converged\n======================================\nJaccard converged in 10 iterations\nJaccard take 71.40520787239075  to converged\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Q4-1: Compare the SSEs : when there is no change in centroid position","metadata":{}},{"cell_type":"code","source":"class KMeans:\n    def __init__(self, k=10, max_iter=100, distance_metric=euclidean_distance, seed=99):\n        self.k = k\n        self.max_iter = max_iter\n        self.distance_metric = distance_metric\n        self.seed = seed\n\n    def fit(self, data):\n        np.random.seed(self.seed)\n        rowNum = data.shape[0]\n        self.centroids = data[np.random.choice(rowNum, self.k, replace=False)]\n        \n        prev_centroids = None\n        for i in range(self.max_iter):\n            clusters = []\n            for _ in range(self.k):\n                clusters.append([])\n                \n            for datapoint in data:\n                distances = cdist(datapoint.reshape(1, -1), self.centroids, metric=self.distance_metric)\n                cluster = np.argmin(distances)\n                clusters[cluster].append(datapoint)\n          \n            prev_centroids = self.centroids.copy()\n            self.centroids = [np.mean(cluster, axis=0) for cluster in clusters]\n            if np.allclose(prev_centroids, self.centroids):\n                break\n\n    def predict(self, data):\n        distances = []\n        for datapoint in data:\n            datapoint_distances = []\n            for centroid in self.centroids:\n                distance = self.distance_metric(datapoint, centroid)\n                datapoint_distances.append(distance)\n            distances.append(datapoint_distances)\n        distances = np.array(distances)\n        return np.argmin(distances, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:14:05.053804Z","iopub.execute_input":"2024-03-31T21:14:05.054375Z","iopub.status.idle":"2024-03-31T21:14:05.072765Z","shell.execute_reply.started":"2024-03-31T21:14:05.054327Z","shell.execute_reply":"2024-03-31T21:14:05.070998Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"euclideanKM = KMeans(k=10, max_iter=100, distance_metric=euclidean_distance, seed=99)\neuclideanKM.fit(data)\neuclidean_sse = np.sum(np.min(cdist(data, euclideanKM.centroids, 'euclidean'), axis=1)**2)\n\n\ncosineKM = KMeans(k=10, max_iter=100, distance_metric=cosine_similarity, seed=99)\ncosineKM.fit(data)\ncosine_sse = np.sum(np.min(cdist(data, cosineKM.centroids, 'cosine'), axis=1)**2)\n\n\njaccardKM = KMeans(k=10, max_iter=100, distance_metric=jaccard_similarity, seed=99)\njaccardKM.fit(data)\njaccard_sse = np.sum(np.min(cdist(data, jaccardKM.centroids, 'jaccard'), axis=1)**2)\n\nprint(\"Euclidean SSE:\", euclidean_sse)\nprint(\"Cosine SSE:\", cosine_sse)\nprint(\"Jaccard SSE:\", jaccard_sse)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:14:05.075069Z","iopub.execute_input":"2024-03-31T21:14:05.075576Z","iopub.status.idle":"2024-03-31T21:26:16.889088Z","shell.execute_reply.started":"2024-03-31T21:14:05.075506Z","shell.execute_reply":"2024-03-31T21:26:16.887597Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Euclidean SSE: 25408545285.977436\nCosine SSE: 684.4072012471529\nJaccard SSE: 9999.69801786809\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Q4-2: Compare the SSEs : when the SSE value increases in the next iteration","metadata":{}},{"cell_type":"code","source":"class KMeans:\n    def __init__(self, k=10, max_iter=100, distance_metric=euclidean_distance, seed=99):\n        self.k = k\n        self.max_iter = max_iter\n        self.distance_metric = distance_metric\n        self.seed = seed\n\n    def fit(self, data):\n        np.random.seed(self.seed)\n        rowNum = data.shape[0]\n        self.centroids = data[np.random.choice(rowNum, self.k, replace=False)]\n        \n        prev_centroids = None\n        prev_sse = float('inf')\n        \n        for i in range(self.max_iter):\n            clusters = []\n            for _ in range(self.k):\n                clusters.append([])\n                \n            for datapoint in data:\n                distances = cdist(datapoint.reshape(1, -1), self.centroids, metric=self.distance_metric)\n                cluster = np.argmin(distances)\n                clusters[cluster].append(datapoint)\n                \n            prev_centroids = self.centroids.copy()\n            self.centroids = [np.mean(cluster, axis=0) for cluster in clusters]\n            sse = np.sum([np.sum(cdist(cluster, centroid.reshape(1,-1), metric=self.distance_metric)**2) for cluster, centroid in zip(clusters, self.centroids)])\n            \n            if sse > prev_sse:\n                break\n            prev_sse = sse\n            \n            if np.allclose(prev_centroids, self.centroids):\n                break\n\n    def predict(self, data):\n        distances = []\n        for datapoint in data:\n            datapoint_distances = []\n            for centroid in self.centroids:\n                distance = self.distance_metric(datapoint, centroid)\n                datapoint_distances.append(distance)\n            distances.append(datapoint_distances)\n        distances = np.array(distances)\n        return np.argmin(distances, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:26:16.890925Z","iopub.execute_input":"2024-03-31T21:26:16.891358Z","iopub.status.idle":"2024-03-31T21:26:16.908516Z","shell.execute_reply.started":"2024-03-31T21:26:16.891318Z","shell.execute_reply":"2024-03-31T21:26:16.907192Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"euclideanKM = KMeans(k=10, max_iter=100, distance_metric=euclidean_distance, seed=99)\neuclideanKM.fit(data)\neuclidean_sse = np.sum(np.min(cdist(data, euclideanKM.centroids, 'euclidean'), axis=1)**2)\n\n\ncosineKM = KMeans(k=10, max_iter=100, distance_metric=cosine_similarity, seed=99)\ncosineKM.fit(data)\ncosine_sse = np.sum(np.min(cdist(data, cosineKM.centroids, 'cosine'), axis=1)**2)\n\n\njaccardKM = KMeans(k=10, max_iter=100, distance_metric=jaccard_similarity, seed=99)\njaccardKM.fit(data)\njaccard_sse = np.sum(np.min(cdist(data, jaccardKM.centroids, 'jaccard'), axis=1)**2)\n\nprint(\"Euclidean SSE:\", euclidean_sse)\nprint(\"Cosine SSE:\", cosine_sse)\nprint(\"Jaccard SSE:\", jaccard_sse)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:26:16.910330Z","iopub.execute_input":"2024-03-31T21:26:16.910916Z","iopub.status.idle":"2024-03-31T21:36:01.587338Z","shell.execute_reply.started":"2024-03-31T21:26:16.910866Z","shell.execute_reply":"2024-03-31T21:36:01.585803Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Euclidean SSE: 25408545285.977436\nCosine SSE: 684.4072012471529\nJaccard SSE: 9999.727602183244\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Q4-3: Compare the SSEs : when the maximum preset value (e.g., 100) of iteration is complete","metadata":{}},{"cell_type":"code","source":"class KMeans:\n    def __init__(self, k=10, max_iter=100, distance_metric=euclidean_distance, seed=99):\n        self.k = k\n        self.max_iter = max_iter\n        self.distance_metric = distance_metric\n        self.seed = seed\n\n    def fit(self, data):\n        np.random.seed(self.seed)\n        rowNum = data.shape[0]\n        self.centroids = data[np.random.choice(rowNum, self.k, replace=False)]\n        \n        prev_centroids = None\n        for i in range(self.max_iter):\n            clusters = []\n            for _ in range(self.k):\n                clusters.append([])\n                \n            for datapoint in data:\n                distances = cdist(datapoint.reshape(1, -1), self.centroids, metric=self.distance_metric)\n                cluster = np.argmin(distances)\n                clusters[cluster].append(datapoint)\n                \n            prev_centroids = self.centroids.copy()\n            self.centroids = [np.mean(cluster, axis=0) for cluster in clusters]\n            \n            if np.allclose(prev_centroids, self.centroids):\n                break\n                \n            elif i == self.max_iter-1:\n                print(f\"KMeans did not converge in {self.max_iter} iterations\")\n                break\n\n    def predict(self, data):\n        distances = []\n        for datapoint in data:\n            datapoint_distances = []\n            for centroid in self.centroids:\n                distance = self.distance_metric(datapoint, centroid)\n                datapoint_distances.append(distance)\n            distances.append(datapoint_distances)\n        distances = np.array(distances)\n        return np.argmin(distances, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:36:01.589184Z","iopub.execute_input":"2024-03-31T21:36:01.589625Z","iopub.status.idle":"2024-03-31T21:36:01.606248Z","shell.execute_reply.started":"2024-03-31T21:36:01.589573Z","shell.execute_reply":"2024-03-31T21:36:01.604660Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"euclideanKM = KMeans(k=10, max_iter=100, distance_metric=euclidean_distance, seed=99)\neuclideanKM.fit(data)\neuclidean_sse = np.sum(np.min(cdist(data, euclideanKM.centroids, 'euclidean'), axis=1)**2)\n\n\ncosineKM = KMeans(k=10, max_iter=100, distance_metric=cosine_similarity, seed=99)\ncosineKM.fit(data)\ncosine_sse = np.sum(np.min(cdist(data, cosineKM.centroids, 'cosine'), axis=1)**2)\n\n\njaccardKM = KMeans(k=10, max_iter=100, distance_metric=jaccard_similarity, seed=99)\njaccardKM.fit(data)\njaccard_sse = np.sum(np.min(cdist(data, jaccardKM.centroids, 'jaccard'), axis=1)**2)\n\nprint(\"Euclidean SSE:\", euclidean_sse)\nprint(\"Cosine SSE:\", cosine_sse)\nprint(\"Jaccard SSE:\", jaccard_sse)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T21:36:01.607944Z","iopub.execute_input":"2024-03-31T21:36:01.608342Z","iopub.status.idle":"2024-03-31T21:48:11.483406Z","shell.execute_reply.started":"2024-03-31T21:36:01.608312Z","shell.execute_reply":"2024-03-31T21:48:11.481829Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"KMeans did not converge in 100 iterations\nKMeans did not converge in 100 iterations\nKMeans did not converge in 100 iterations\nEuclidean SSE: 25408545285.977436\nCosine SSE: 684.4072012471529\nJaccard SSE: 9999.69801786809\n","output_type":"stream"}]}]}