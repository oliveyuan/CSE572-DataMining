{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7986401,"sourceType":"datasetVersion","datasetId":4701131}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## test 2","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport time\nfrom scipy.spatial.distance import cdist","metadata":{"execution":{"iopub.status.busy":"2024-03-31T22:54:07.932279Z","iopub.execute_input":"2024-03-31T22:54:07.932828Z","iopub.status.idle":"2024-03-31T22:54:09.613286Z","shell.execute_reply.started":"2024-03-31T22:54:07.932785Z","shell.execute_reply":"2024-03-31T22:54:09.612023Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/hw3-data/data.csv\",header=None).values\nlabel = pd.read_csv(\"/kaggle/input/hw3-data/label.csv\",header=None).values.reshape(-1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T22:54:09.615628Z","iopub.execute_input":"2024-03-31T22:54:09.616109Z","iopub.status.idle":"2024-03-31T22:54:10.668088Z","shell.execute_reply.started":"2024-03-31T22:54:09.616077Z","shell.execute_reply":"2024-03-31T22:54:10.667019Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Q1 : Compare the SSEs","metadata":{}},{"cell_type":"code","source":"# ======== Euclidean =========\ndef euclidean_distance(a, b):\n    return np.linalg.norm(a - b)\n\n# ======== 1 - cosine =========\ndef cosine_similarity(a, b):\n    return 1 - np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\n# ======== 1 - jaccard =========\ndef jaccard_similarity(a, b):\n    return 1 - np.sum(np.minimum(a, b)) / np.sum(np.maximum(a, b))","metadata":{"execution":{"iopub.status.busy":"2024-03-31T22:54:10.669683Z","iopub.execute_input":"2024-03-31T22:54:10.670273Z","iopub.status.idle":"2024-03-31T22:54:10.677824Z","shell.execute_reply.started":"2024-03-31T22:54:10.670239Z","shell.execute_reply":"2024-03-31T22:54:10.676849Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# ======== K_Means Class =========\ndef KMeans(data, k, similarity, max_iterations=500):\n    #======= init get random centroid =========\n    centroids = random.sample(list(data), k)\n    iterations = 0\n    pre_sse = 0\n    \n    while True:\n        # ========== Assign data point to its closest centroid ==========\n        clusters = [[] for i in range(k)]\n        for datapoint in data:\n            distances = [similarity(datapoint, centroid) for centroid in centroids]\n            cluster_index = np.argmin(distances)\n            clusters[cluster_index].append(datapoint)\n        \n        # ========== Calculate new centroid for each cluster ============\n        new_centroids = []\n        \n        # ========== Calculate SSE ============\n        sse = 0\n        for i in range(k):\n            cluster = clusters[i]\n            if len(cluster) == 0:\n                new_centroids.append(centroids[i])\n                continue\n            centroid = np.mean(cluster, axis=0)\n            new_centroids.append(centroid)\n            sse += np.sum([similarity(datapoint, centroid) for datapoint in cluster])\n        \n        # ============== Check for convergence ===========\n        if np.allclose(new_centroids, centroids) or sse >= pre_sse or iterations >= max_iterations:\n            break\n        \n        # ============ Update the centroids & SSE =============\n        centroids = new_centroids\n        pre_sse = sse\n        iterations += 1\n    \n    return clusters, centroids, sse","metadata":{"execution":{"iopub.status.busy":"2024-03-31T22:54:10.679767Z","iopub.execute_input":"2024-03-31T22:54:10.680153Z","iopub.status.idle":"2024-03-31T22:54:10.694193Z","shell.execute_reply.started":"2024-03-31T22:54:10.680121Z","shell.execute_reply":"2024-03-31T22:54:10.692546Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"k = len(np.unique(label))\nprint(\"k = \", k)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T22:54:10.699222Z","iopub.execute_input":"2024-03-31T22:54:10.699773Z","iopub.status.idle":"2024-03-31T22:54:10.711931Z","shell.execute_reply.started":"2024-03-31T22:54:10.699734Z","shell.execute_reply":"2024-03-31T22:54:10.710280Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"k =  10\n","output_type":"stream"}]},{"cell_type":"code","source":"clusters_euclidean, centroids_euclidean, sse_euclidean = KMeans(data, k, euclidean_distance)\nclusters_cosine, centroids_cosine, sse_cosine = KMeans(data, k, cosine_similarity)\nclusters_jaccard, centroids_jaccard, sse_jaccard = KMeans(data, k, jaccard_similarity)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T22:54:10.713903Z","iopub.execute_input":"2024-03-31T22:54:10.714300Z","iopub.status.idle":"2024-03-31T22:54:17.816935Z","shell.execute_reply.started":"2024-03-31T22:54:10.714268Z","shell.execute_reply":"2024-03-31T22:54:17.815675Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(\"Euclidean SSE =  \", sse_euclidean)\nprint(\"Cosine SSE =  \", sse_cosine)\nprint(\"Jaccard SSE =  \", sse_jaccard)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T22:54:17.818810Z","iopub.execute_input":"2024-03-31T22:54:17.819277Z","iopub.status.idle":"2024-03-31T22:54:17.827262Z","shell.execute_reply.started":"2024-03-31T22:54:17.819235Z","shell.execute_reply":"2024-03-31T22:54:17.825516Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Euclidean SSE =   16677378.831301842\nCosine SSE =   2855.987934432367\nJaccard SSE =   6475.504613248713\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Q2 : Compare the accuracies","metadata":{}},{"cell_type":"code","source":"class KMeans:\n    def __init__(self, k=10, max_iter=100, distance_metric=euclidean_distance):\n        self.k = k\n        self.max_iter = max_iter\n        self.distance_metric = distance_metric\n   \n    # ============== fit for KMeans Model ===========\n    def fit(self, data):\n        # ==== init centroids ===\n        rowNum = data.shape[0]\n        self.centroids = data[np.random.choice(rowNum, self.k, replace=False)]\n        \n        \n        for i in range(self.max_iter):\n            \n            clusters = []\n            for _ in range(self.k):\n                clusters.append([])\n            \n            for datapoint in data:\n                #  ====== calculates distance to each centroid =========\n                distances = [self.distance_metric(datapoint, centroid) for centroid in self.centroids]\n                cluster = np.argmin(distances)\n                 #  ====== assigns the data point to the nearest centroid's cluster ========= \n                clusters[cluster].append(datapoint)\n                \n            new_centroids = []\n            for cluster in clusters:\n                if len(cluster) == 0:\n                    new_centroids.append(np.zeros(data.shape[1]))\n                else:\n                    new_centroids.append(np.mean(cluster, axis=0))\n                    \n            # ============== Check for convergence ===========\n            if np.allclose(self.centroids, new_centroids):\n                break\n            self.centroids = new_centroids\n    \n    # ============== Predict class ===========\n    def predict(self, data):\n        distances = []\n        for datapoint in data:\n            datapoint_distances = []\n            for centroid in self.centroids:\n                distance = self.distance_metric(datapoint, centroid)\n                datapoint_distances.append(distance)\n            distances.append(datapoint_distances)\n        distances = np.array(distances)\n        return np.argmin(distances, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T22:54:17.829331Z","iopub.execute_input":"2024-03-31T22:54:17.829721Z","iopub.status.idle":"2024-03-31T22:54:17.847592Z","shell.execute_reply.started":"2024-03-31T22:54:17.829690Z","shell.execute_reply":"2024-03-31T22:54:17.845950Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# ========Accuracy class=========\ndef Accuracy(predicted, actual):\n    count = 0\n    total = len(label)\n    for i in range(total):\n        if predicted[i] == actual[i]:\n            count += 1\n    return (count/total)*100","metadata":{"execution":{"iopub.status.busy":"2024-03-31T22:54:17.849664Z","iopub.execute_input":"2024-03-31T22:54:17.850015Z","iopub.status.idle":"2024-03-31T22:54:17.861261Z","shell.execute_reply.started":"2024-03-31T22:54:17.849986Z","shell.execute_reply":"2024-03-31T22:54:17.859906Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# ========euclidean predictions=========\neuclideanKM = KMeans(k=10, max_iter=100, distance_metric=euclidean_distance)\neuclideanKM.fit(data)\neuclidean_predictions = euclideanKM.predict(data)\n\n# ========cosine predictions=========\ncosineKM = KMeans(k=10, max_iter=100, distance_metric=cosine_similarity)\ncosineKM.fit(data)\ncosine_predictions = cosineKM.predict(data)\n\n# ========jaccard  predictions=========\njaccardKM = KMeans(k=10, max_iter=100, distance_metric=jaccard_similarity)\njaccardKM.fit(data)\njaccard_predictions = jaccardKM.predict(data)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T22:54:17.863065Z","iopub.execute_input":"2024-03-31T22:54:17.863389Z","iopub.status.idle":"2024-03-31T23:00:04.249932Z","shell.execute_reply.started":"2024-03-31T22:54:17.863362Z","shell.execute_reply":"2024-03-31T23:00:04.248379Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(\"Euclidean accuracy = \",Accuracy(euclidean_predictions,label))\nprint(\"Cosine accuracy = \",Accuracy(cosine_predictions,label))\nprint(\"Jaccard accuracy = \",Accuracy(jaccard_predictions,label))","metadata":{"execution":{"iopub.status.busy":"2024-03-31T23:00:04.251505Z","iopub.execute_input":"2024-03-31T23:00:04.252012Z","iopub.status.idle":"2024-03-31T23:00:04.279160Z","shell.execute_reply.started":"2024-03-31T23:00:04.251972Z","shell.execute_reply":"2024-03-31T23:00:04.277783Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Euclidean accuracy =  2.29\nCosine accuracy =  16.37\nJaccard accuracy =  7.580000000000001\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Q3: Set up the same stop criteria, get iterations and times to converge","metadata":{}},{"cell_type":"code","source":"class KMeans:\n    def __init__(self, k=10, max_iter=100, distance_metric=euclidean_distance, seed=99):\n        self.k = k\n        self.max_iter = max_iter\n        self.distance_metric = distance_metric\n        self.seed = seed\n    \n    def fit(self, data):\n        \n        # ===== Set the seed for NumPy's random number generator ====\n        np.random.seed(self.seed)\n        rowNum = data.shape[0]\n        self.centroids = data[np.random.choice(rowNum, self.k, replace=False)]\n        \n        prev_sse = np.inf\n        start_time = time.time()\n        for i in range(self.max_iter):\n            clusters = []\n            for _ in range(self.k):\n                clusters.append([])\n                \n            for datapoint in data:\n                distances = [self.distance_metric(datapoint, centroid) for centroid in self.centroids]\n                cluster = np.argmin(distances)\n                clusters[cluster].append(datapoint)\n            new_centroids = []\n            \n            for cluster in clusters:\n                if len(cluster) == 0:\n                    new_centroids.append(np.zeros(X.shape[1]))\n                else:\n                    new_centroids.append(np.mean(cluster, axis=0))\n            \n            \n            sse = 0\n            for cluster, centroid in zip(clusters, new_centroids):\n                sse += np.sum((cluster - centroid) ** 2)\n                \n            # ==== no change in centroid position OR SSE value increases in the next iteration ====\n            if np.allclose(self.centroids, new_centroids) or sse > prev_sse:\n                break\n                \n            self.centroids = new_centroids\n            prev_sse = sse\n    \n        end_time = time.time() \n        self.convergence_time = end_time - start_time\n            \n    def predict(self, data):\n        distances = []\n        for datapoint in data:\n            datapoint_distances = []\n            for centroid in self.centroids:\n                distance = self.distance_metric(datapoint, centroid)\n                datapoint_distances.append(distance)\n            distances.append(datapoint_distances)\n        distances = np.array(distances)\n        return np.argmin(distances, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T23:00:04.282719Z","iopub.execute_input":"2024-03-31T23:00:04.283180Z","iopub.status.idle":"2024-03-31T23:00:04.301092Z","shell.execute_reply.started":"2024-03-31T23:00:04.283142Z","shell.execute_reply":"2024-03-31T23:00:04.299459Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"euclideanKM = KMeans(k=10, max_iter=500, distance_metric=euclidean_distance)\neuclideanKM.fit(data)\n\ncosineKM = KMeans(k=10, max_iter=500, distance_metric=cosine_similarity)\ncosineKM.fit(data)\n\njaccardKM = KMeans(k=10, max_iter=500, distance_metric=jaccard_similarity)\njaccardKM.fit(data)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T23:00:04.304965Z","iopub.execute_input":"2024-03-31T23:00:04.306170Z","iopub.status.idle":"2024-03-31T23:04:48.732786Z","shell.execute_reply.started":"2024-03-31T23:00:04.306127Z","shell.execute_reply":"2024-03-31T23:04:48.731100Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(\"Euclidean converged in {} iterations\".format(len(euclideanKM.centroids)))\nprint(\"Euclidean take {}\".format(euclideanKM.convergence_time), \" to converged\")\nprint(\"======================================\")\nprint(\"Cosine converged in {} iterations\".format(len(cosineKM.centroids)))\nprint(\"Cosine take {}\".format(cosineKM.convergence_time), \" to converged\")\nprint(\"======================================\")\nprint(\"Jaccard converged in {} iterations\".format(len(jaccardKM.centroids)))\nprint(\"Jaccard take {}\".format(jaccardKM.convergence_time), \" to converged\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T23:04:48.737959Z","iopub.execute_input":"2024-03-31T23:04:48.738376Z","iopub.status.idle":"2024-03-31T23:04:48.748848Z","shell.execute_reply.started":"2024-03-31T23:04:48.738345Z","shell.execute_reply":"2024-03-31T23:04:48.747040Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Euclidean converged in 10 iterations\nEuclidean take 145.40334057807922  to converged\n======================================\nCosine converged in 10 iterations\nCosine take 72.48465156555176  to converged\n======================================\nJaccard converged in 10 iterations\nJaccard take 66.51960730552673  to converged\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Q4-1: Compare the SSEs : when there is no change in centroid position","metadata":{}},{"cell_type":"code","source":"class KMeans:\n    def __init__(self, k=10, max_iter=100, distance_metric=euclidean_distance, seed=99):\n        self.k = k\n        self.max_iter = max_iter\n        self.distance_metric = distance_metric\n        self.seed = seed\n\n    def fit(self, data):\n        np.random.seed(self.seed)\n        rowNum = data.shape[0]\n        self.centroids = data[np.random.choice(rowNum, self.k, replace=False)]\n        \n        prev_centroids = None\n        for i in range(self.max_iter):\n            clusters = []\n            for _ in range(self.k):\n                clusters.append([])\n                \n            for datapoint in data:\n                distances = cdist(datapoint.reshape(1, -1), self.centroids, metric=self.distance_metric)\n                cluster = np.argmin(distances)\n                clusters[cluster].append(datapoint)\n          \n            prev_centroids = self.centroids.copy()\n            self.centroids = [np.mean(cluster, axis=0) for cluster in clusters]\n            if np.allclose(prev_centroids, self.centroids):\n                break\n\n    def predict(self, data):\n        distances = []\n        for datapoint in data:\n            datapoint_distances = []\n            for centroid in self.centroids:\n                distance = self.distance_metric(datapoint, centroid)\n                datapoint_distances.append(distance)\n            distances.append(datapoint_distances)\n        distances = np.array(distances)\n        return np.argmin(distances, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T23:04:48.750454Z","iopub.execute_input":"2024-03-31T23:04:48.750837Z","iopub.status.idle":"2024-03-31T23:04:48.769447Z","shell.execute_reply.started":"2024-03-31T23:04:48.750806Z","shell.execute_reply":"2024-03-31T23:04:48.767569Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"euclideanKM = KMeans(k=10, max_iter=100, distance_metric=euclidean_distance, seed=99)\neuclideanKM.fit(data)\neuclidean_sse = np.sum(np.min(cdist(data, euclideanKM.centroids, 'euclidean'), axis=1)**2)\n\n\ncosineKM = KMeans(k=10, max_iter=100, distance_metric=cosine_similarity, seed=99)\ncosineKM.fit(data)\ncosine_sse = np.sum(np.min(cdist(data, cosineKM.centroids, 'cosine'), axis=1)**2)\n\n\njaccardKM = KMeans(k=10, max_iter=100, distance_metric=jaccard_similarity, seed=99)\njaccardKM.fit(data)\njaccard_sse = np.sum(np.min(cdist(data, jaccardKM.centroids, 'jaccard'), axis=1)**2)\n\nprint(\"Euclidean SSE:\", euclidean_sse)\nprint(\"Cosine SSE:\", cosine_sse)\nprint(\"Jaccard SSE:\", jaccard_sse)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T23:04:48.771689Z","iopub.execute_input":"2024-03-31T23:04:48.772121Z","iopub.status.idle":"2024-03-31T23:16:29.064997Z","shell.execute_reply.started":"2024-03-31T23:04:48.772088Z","shell.execute_reply":"2024-03-31T23:16:29.063779Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Euclidean SSE: 25408545285.977436\nCosine SSE: 684.4072012471529\nJaccard SSE: 9999.69801786809\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Q4-2: Compare the SSEs : when the SSE value increases in the next iteration","metadata":{}},{"cell_type":"code","source":"class KMeans:\n    def __init__(self, k=10, max_iter=100, distance_metric=euclidean_distance, seed=99):\n        self.k = k\n        self.max_iter = max_iter\n        self.distance_metric = distance_metric\n        self.seed = seed\n\n    def fit(self, data):\n        np.random.seed(self.seed)\n        rowNum = data.shape[0]\n        self.centroids = data[np.random.choice(rowNum, self.k, replace=False)]\n        \n        prev_centroids = None\n        prev_sse = float('inf')\n        \n        for i in range(self.max_iter):\n            clusters = []\n            for _ in range(self.k):\n                clusters.append([])\n                \n            for datapoint in data:\n                distances = cdist(datapoint.reshape(1, -1), self.centroids, metric=self.distance_metric)\n                cluster = np.argmin(distances)\n                clusters[cluster].append(datapoint)\n                \n            prev_centroids = self.centroids.copy()\n            self.centroids = [np.mean(cluster, axis=0) for cluster in clusters]\n            sse = np.sum([np.sum(cdist(cluster, centroid.reshape(1,-1), metric=self.distance_metric)**2) for cluster, centroid in zip(clusters, self.centroids)])\n            \n            if sse > prev_sse:\n                break\n            prev_sse = sse\n            \n            if np.allclose(prev_centroids, self.centroids):\n                break\n\n    def predict(self, data):\n        distances = []\n        for datapoint in data:\n            datapoint_distances = []\n            for centroid in self.centroids:\n                distance = self.distance_metric(datapoint, centroid)\n                datapoint_distances.append(distance)\n            distances.append(datapoint_distances)\n        distances = np.array(distances)\n        return np.argmin(distances, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T23:16:29.066671Z","iopub.execute_input":"2024-03-31T23:16:29.067026Z","iopub.status.idle":"2024-03-31T23:16:29.084456Z","shell.execute_reply.started":"2024-03-31T23:16:29.066996Z","shell.execute_reply":"2024-03-31T23:16:29.082925Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"euclideanKM = KMeans(k=10, max_iter=100, distance_metric=euclidean_distance, seed=99)\neuclideanKM.fit(data)\neuclidean_sse = np.sum(np.min(cdist(data, euclideanKM.centroids, 'euclidean'), axis=1)**2)\n\n\ncosineKM = KMeans(k=10, max_iter=100, distance_metric=cosine_similarity, seed=99)\ncosineKM.fit(data)\ncosine_sse = np.sum(np.min(cdist(data, cosineKM.centroids, 'cosine'), axis=1)**2)\n\n\njaccardKM = KMeans(k=10, max_iter=100, distance_metric=jaccard_similarity, seed=99)\njaccardKM.fit(data)\njaccard_sse = np.sum(np.min(cdist(data, jaccardKM.centroids, 'jaccard'), axis=1)**2)\n\nprint(\"Euclidean SSE:\", euclidean_sse)\nprint(\"Cosine SSE:\", cosine_sse)\nprint(\"Jaccard SSE:\", jaccard_sse)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T23:16:29.086663Z","iopub.execute_input":"2024-03-31T23:16:29.087143Z","iopub.status.idle":"2024-03-31T23:25:49.276132Z","shell.execute_reply.started":"2024-03-31T23:16:29.087101Z","shell.execute_reply":"2024-03-31T23:25:49.274472Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Euclidean SSE: 25408545285.977436\nCosine SSE: 684.4072012471529\nJaccard SSE: 9999.727602183244\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Q4-3: Compare the SSEs : when the maximum preset value (e.g., 100) of iteration is complete","metadata":{}},{"cell_type":"code","source":"class KMeans:\n    def __init__(self, k=10, max_iter=100, distance_metric=euclidean_distance, seed=99):\n        self.k = k\n        self.max_iter = max_iter\n        self.distance_metric = distance_metric\n        self.seed = seed\n\n    def fit(self, data):\n        np.random.seed(self.seed)\n        rowNum = data.shape[0]\n        self.centroids = data[np.random.choice(rowNum, self.k, replace=False)]\n        \n        prev_centroids = None\n        for i in range(self.max_iter):\n            clusters = []\n            for _ in range(self.k):\n                clusters.append([])\n                \n            for datapoint in data:\n                distances = cdist(datapoint.reshape(1, -1), self.centroids, metric=self.distance_metric)\n                cluster = np.argmin(distances)\n                clusters[cluster].append(datapoint)\n                \n            prev_centroids = self.centroids.copy()\n            self.centroids = [np.mean(cluster, axis=0) for cluster in clusters]\n            \n            if np.allclose(prev_centroids, self.centroids):\n                break\n                \n            elif i == self.max_iter-1:\n                print(f\"KMeans did not converge in {self.max_iter} iterations\")\n                break\n\n    def predict(self, data):\n        distances = []\n        for datapoint in data:\n            datapoint_distances = []\n            for centroid in self.centroids:\n                distance = self.distance_metric(datapoint, centroid)\n                datapoint_distances.append(distance)\n            distances.append(datapoint_distances)\n        distances = np.array(distances)\n        return np.argmin(distances, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T23:25:49.277853Z","iopub.execute_input":"2024-03-31T23:25:49.278212Z","iopub.status.idle":"2024-03-31T23:25:49.294717Z","shell.execute_reply.started":"2024-03-31T23:25:49.278183Z","shell.execute_reply":"2024-03-31T23:25:49.292934Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"euclideanKM = KMeans(k=10, max_iter=100, distance_metric=euclidean_distance, seed=99)\neuclideanKM.fit(data)\neuclidean_sse = np.sum(np.min(cdist(data, euclideanKM.centroids, 'euclidean'), axis=1)**2)\n\n\ncosineKM = KMeans(k=10, max_iter=100, distance_metric=cosine_similarity, seed=99)\ncosineKM.fit(data)\ncosine_sse = np.sum(np.min(cdist(data, cosineKM.centroids, 'cosine'), axis=1)**2)\n\n\njaccardKM = KMeans(k=10, max_iter=100, distance_metric=jaccard_similarity, seed=99)\njaccardKM.fit(data)\njaccard_sse = np.sum(np.min(cdist(data, jaccardKM.centroids, 'jaccard'), axis=1)**2)\n\nprint(\"Euclidean SSE:\", euclidean_sse)\nprint(\"Cosine SSE:\", cosine_sse)\nprint(\"Jaccard SSE:\", jaccard_sse)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T23:25:49.297011Z","iopub.execute_input":"2024-03-31T23:25:49.297464Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"KMeans did not converge in 100 iterations\n","output_type":"stream"}]}]}